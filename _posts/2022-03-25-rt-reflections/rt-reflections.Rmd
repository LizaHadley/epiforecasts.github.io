---
title: "Reflections on two years estimating effective reproduction numbers"
description: |
  Over the last two years we have estimated reproduction numbers daily for several thousand locations, presented these estimates as a curated data set and visualised them at epiforecasts.io/covid. In this post we reflect on this project, summarising its utility, its integration with other projects, unanticipated challenges, and finally whether we would do it again.
author:
  - name: Sebastian Funk
    url: https://www.lshtm.ac.uk/aboutus/people/funk.sebastian
    affiliation: London School of Hygiene and Tropical Medicine
    affiliation_url: https://www.lshtm.ac.uk/
  - name: Sam Abbott
    url: https://samabbott.co.uk
    affiliation: London School of Hygiene and Tropical Medicine
    affiliation_url: https://www.lshtm.ac.uk/
  - name: Sebastian Funk
    url: https://www.lshtm.ac.uk/aboutus/people/funk.sebastian
    affiliation: London School of Hygiene and Tropical Medicine
    affiliation_url: https://www.lshtm.ac.uk/
date: 2022-03-25
output:
  distill::distill_article:
    self_contained: false
    toc: true
creative_commons: CC BY
twitter:
  site: "@epiforecasts"
  creator: "@sbfnk"
bibliography: biblio.bib
---


31 March, a week from today 2 weeks from today, will mark the last day we are producing global national and subnational Rt estimates and nowcasts at https://epiforecasts.io/covid/posts/global/ - more than 2 years after we published the first set of estimates. This is a good opportunity to reflect on what we have learned from this, what went well and what went wrong, and what we would aim to do better next time.

## An attempt to design a useful resource for situational awareness

We started this with the aim to provide both decision makers and the general public with real-time information on how the epidemic was progressing initially in China, then in a small subset of countries, and ultimately in different parts of the world across different scales. We felt at the time that the most useful quantity to estimate was the time-varying reproduction number Rt, as it characterises the exponential behaviour of transmission, captures some of the known epidemiology of infectious diseases, and can be used to quantify both the scale of the effort required to turn over an epidemic. 

In order to estimate this from the surveillance case data being published by countries around the world and collated by [Johns Hopkins University](https://coronavirus.jhu.edu/data), we had to develop methods [@rtwebsite-1; @rtwebsite-2] that account for reporting artefacts and delays whilst taking into account emerging insights on the epidemiology of SARS-CoV-2, especially incubation and generation times. Our initial methodology was developed in the first few months of the pandemic (released in the `EpiNow` R package[@epinow]^[Documentation here: https://epiforecasts.io/EpiNow]), with our updated approach (released in the `EpiNow2` R package[@epinow2]^[Documentation here: https://epiforecasts.io/EpiNow2])  being developed after discussions with colleagues on the limitations of our original implementation [@Gostic2020-vw]. These packages ended up being the workhorses behind the web site and were used to provide daily updates of the estimates for almost all countries of the world, as well as several subnational geographies that we added over time.

```{r, echo = FALSE, fig.cap = "An example figure showing effective reproduction number estimates over time from a subset of countries."}
knitr::include_graphics("example-rt.png")
```


## Assessing utility

So was it useful? Hard to tell. The website where we presented our estimates has had just over 500 thousand unique users since April 2020 with 1.2 million page views (with 800 thousand of these being for our US estimates, 120 thousand for our global estimates, and only 20 thousand for our methods). Usage has reduced over time but 8 thousand unique users still accessed the site in the last month.

The estimates themselves were processed regularly by various national international organisations such as the WHO, especially in the early parts of the epidemic. That said, we donâ€™t know whether any of this gave any policy maker any useful information that helped them make better decisions or helped inform members of the public about their individual risk. Even if our estimates did help inform decision makers it is also not clear how much the evidence from our estimates improved on that available from other sources.

In its current and now final form, the web site still provides a somewhat unique resource for tracking the epidemic as we are not aware of another dashboard that collates both national and subnational Rt estimates from across the globe. That said, other websites like [ourworldindata](https://ourworldindata.org/coronavirus) or the [UK dashboard](https://coronavirus.data.gov.uk/) present more comprehensive raw surveillance information in a more interactive way, arguably rendering large parts of our public facing work obsolete.


## Feeding into analysis pipelines

A perhaps more valuable contribution of our work was the publication of the estimates in numerical form that we provided on [github](https://github.com/epiforecasts/covid-rt-estimates) alongside the visualisations on the web site. It was used in [numerous publications](https://scholar.google.co.uk/scholar?oi=bibs&hl=en&cites=101206636044215432,8611489539131682391&as_sdt=5), including some by researchers that did not interact with us, making it hard for us to assess whether they were fully aware of the limitations underlying the estimates.

We used the estimates ourselves in various downstream analyses, e.g. to [monitor or local variation](https://github.com/epiforecasts/covid19_uk_local), to estimate transmission advantage of new variants(for [Alpha](https://doi.org/10.1126/science.abg3055), and for [Delta](https://doi.org/10.1101/2021.11.30.21267056))_ or [estimate severity of infection](https://github.com/epiforecasts/covid19.sgene.utla.rt/blob/severity-analysis/severity-report.pdf) over the course of the epidemic used, among others, used in [this work by Moritz Gerstung](https://doi.org/10.1038/s41586-021-04069-y). Using routinely generated outputs of models as inputs to other models in such pipelines can be useful for multiple reasons.a useful shortcut Primarily, this approach allows for rapid development when novel additions are needed in real-time with each step in the process dealing with some subset of the problem. It can also allow for access to novel methodology to be democratised in a way that is difficult with a complex model as the output can be used with potentially only a limited understanding of the implementation though of course this can cause issues if the limitations of the method are poorly communicated.  We have also observed our estimates being used by researchers from a range of backgrounds, with a range of tools at their disposal, that would be difficult to apply directly to the raw data prior to our domain knowledge based processing. Lastly, for complex problems chaining a series of models into a pipeline can reduce the computational burden and hence make analysis tractable when computational resources are limited. However, this approach may also introduce bias to downstream results, potentially in ways that are diagnose or predict, as it can be difficult to fully incorporate uncertainty from all steps of the analysis pipeline into subsequent steps.

when work is time-pressured and a more suitable model not available, yet it is likely to introduce bias that can be difficult to quantify without more systematic analysis.

## Unanticipated challenges

Our desire to provide a resource that is up-to-date, accurate and comprehensive posed some practical challenges. First of all, any epidemiological estimate is only ever as good as the data and method that is used to produce it. While our method was able to adjust for weekly effects, it hit its limits when e.g. reporting patterns changed or included unprecedented spikes on individual days. The quality, reliability and meaning of the data from different countries varies, and we did not have the capacity to manually curate or interpret the estimates we generated with respect to this underlying variation. Throughout the pandemic we attempted to link with local stakeholders to address some of these issues, including releasing and maintaining an open source data cleaning R package, `covidregionaldata`[@covidregionaldata]^[Documentation here: https://epiforecasts.io/covidregionaldata], but ultimately this was very challenging and we were unable to manage these collaborations effectively.  Because of this we sometimes published nonsensical estimates, and without the capacity to explain how these came about this caused some consternation amongst visitors to the web site. This was a particular issue for subnational estimates in countries without a unified surveillance framework, such as the USA, where reporting patterns and practices changed state by state throughout the pandemic.

Other challenges were of more technical nature. Running a model daily on thousands of national and sub national data sets takes a huge amount of computation when an appropriately complex model is used. We benefited from a very generous grant from Microsoft Data Science for Health that enabled us to do this, and it is the end of that grant that is prompting us to conclude this work. We also received a large amount of help from the UK Met Office in making our set up for distributed computing more sustainable which required a skillset that is difficult to acquire or sustain in academia.

Finally, as for many research groups responding to the pandemic, we have been working significantly over capacity since January 2020. Producing and maintaining these estimates, and the infrastructure that supports them required a significant number of person hours, particularly prior to extensive automation and improvements in the robustness of processes, often out of hours over a prolonged period. This workload often led to more traditional academic work not being done and was likely exacerbated by a lack of the skills required to run complex models in production environments. A particular, and initially surprising, demand on time was responding to feedback from users which could often be complex, linked to public health policy in their region of interest, and sometimes abrupt, aggressive, or extremely negative. 

## Back to 2020â€¦would we do it again?

With all of this in mind we have been reflecting on whether we would do this again given the situation we were facing in early 2020 and, if yes, what we would do differently. Many of the challenges mentioned above were pretty much insurmountable, particularly around data quality and curation. Probably our most useful contributions from this work were in the UK where we knew the data and its limitations particularly well and interacted directly and frequently with policy makers.

That said, it would have been difficult to predict where the focus of our work would be when producing the initial estimates for China. In a perfect world we would have had methodologically robust, well evaluated, and production ready all the tools available to generate epidemiological estimates, and those trained to use them, in advance of a pandemic, such that these could be readily used by ourselves as well as teams everywhere in interaction with local policy makers and with a full understanding of the underlying data and its idiosyncrasies. It is great to see that there are now initiatives towards developing production ready tools for this purpose, and we can only hope that these will be continued to put analytics of future epidemics on a more sustainable and reliable footing. 

However, there appears to be less progress being made on improving the methodological basis for these tools, evaluating their performance in different scenarios (especially low resource settings), and ensuring that there exists a pool of researchers with the right skills to make use of them in real-time and who can also communicate directly with local policy makers. Maintaining, and growing, a pool of skilled researchers able to deploy tools for situational awareness, which requires a different skill set to traditional research, is a particular hurdle as it is poorly supported by current funding models. Without sufficient support some of the progress that has been made developing researchers with these skill sets during the pandemic may be lost.

Ultimately, initiatives of this scale, whether worthwhile or not, are likely to be conducted again and used to inform public health decisions if another epidemic/pandemic occurs. It is in the best interest of the public health community, and the public more generally, that these are as good as possible and not limited by the ability of those implementing them, the availability of computational and personal resources, weaknesses in surveillance systems, or weaknesses in the underlying methodology. 